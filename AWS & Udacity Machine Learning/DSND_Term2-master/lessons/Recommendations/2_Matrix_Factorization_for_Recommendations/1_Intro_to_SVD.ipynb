{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition\n",
    "\n",
    "So far in this lesson, you have gained some exposure to Singular Value Decomposition.  In this notebook, you will get some hands on practice with this technique.\n",
    "\n",
    "Let's get started by reading in our libraries and setting up the data we will be using throughout this notebook\n",
    "\n",
    "`1.` Run the cell below to create the **user_movie_subset** dataframe.  This will be the dataframe you will be using for the first part of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import svd_tests as t\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('../data/movies_clean.csv')\n",
    "reviews = pd.read_csv('../data/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "# Create user-by-item matrix\n",
    "user_items = reviews[['user_id', 'movie_id', 'rating']]\n",
    "user_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "\n",
    "user_movie_subset = user_by_movie[[73486, 75314,  68646, 99685]].dropna(axis=0)\n",
    "print(user_movie_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have the **user_movie_subset** matrix, use this matrix to correctly match each key to the correct value in the dictionary below.  Use the cells below the dictionary as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match each letter to the best statement in the dictionary below - each will be used at most once\n",
    "a = 20\n",
    "b = 68646\n",
    "c = 'The Godfather'\n",
    "d = 'Goodfellas'\n",
    "e = 265\n",
    "f = 30685\n",
    "g = 4\n",
    "\n",
    "sol_1_dict = {\n",
    "    'the number of users in the user_movie_subset': # letter here,\n",
    "    'the number of movies in the user_movie_subset': # letter here,\n",
    "    'the user_id with the highest average ratings given': # letter here,\n",
    "    'the movie_id with the highest average ratings received': # letter here,\n",
    "    'the name of the movie that received the highest average rating': # letter here\n",
    "}\n",
    "\n",
    "\n",
    "#test dictionary here\n",
    "t.test1(sol_1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell for work\n",
    "# user with the highest average rating\n",
    "\n",
    "# movie with highest average rating\n",
    "\n",
    "# list of movie names\n",
    "   \n",
    "# users by movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a little more context about the matrix we will be performing Singular Value Decomposition on, we're going to do just that.  To get started, let's remind ourselves about the dimensions of each of the matrices we are going to get back.   Essentially, we are going to split the **user_movie_subset** matrix into three matrices:\n",
    "\n",
    "$$ U \\Sigma V^T $$\n",
    "\n",
    "\n",
    "`3.` Given what you learned about in the previous parts of this lesson, provide the dimensions for each of the matrices specified above using the dictionary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match each letter in the dictionary below - a letter may appear more than once.\n",
    "a = 'a number that you can choose as the number of latent features to keep'\n",
    "b = 'the number of users'\n",
    "c = 'the number of movies'\n",
    "d = 'the sum of the number of users and movies'\n",
    "e = 'the product of the number of users and movies'\n",
    "\n",
    "sol_2_dict = {\n",
    "    'the number of rows in the U matrix': # letter here, \n",
    "    'the number of columns in the U matrix': # letter here, \n",
    "    'the number of rows in the V transpose matrix': # letter here, \n",
    "    'the number of columns in the V transpose matrix': # letter here\n",
    "}\n",
    "\n",
    "#test dictionary here\n",
    "t.test2(sol_2_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's verify the above dimensions by performing SVD on our user-movie matrix.\n",
    "\n",
    "`4.` Below you can find the code used to perform SVD in numpy.  You can see more about this functionality in the [documentation here](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.svd.html).  What do you notice about the shapes of your matrices?  If you try to take the dot product of the three objects you get back, can you directly do this to get back the user-movie matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u, s, vt = # perform svd here on user_movie_subset\n",
    "s.shape, u.shape, vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell for our thoughts on the questions posted above\n",
    "t.question4thoughts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Use the thoughts from the above question to create **u**, **s**, and **vt** with four latent features.  When you have all three matrices created correctly, run the test below to show that the dot product of the three matrices creates the original user-movie matrix.  The matrices should have the following dimensions:\n",
    "\n",
    "$$ U_{n x k} $$\n",
    "\n",
    "$$\\Sigma_{k x k} $$\n",
    "\n",
    "$$V^T_{k x m} $$\n",
    "\n",
    "where:\n",
    "\n",
    "1. n is the number of users\n",
    "2. k is the number of latent features to keep (4 for this case)\n",
    "3. m is the number of movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the dimensions of u, s, and vt as necessary to use four latent features\n",
    "# update the shape of u and store in u_new\n",
    "u_new = # change the shape of u here\n",
    "\n",
    "# update the shape of s and store in s_new\n",
    "s_new = #change the shape of s as necessary \n",
    "\n",
    "# Because we are using 4 latent features and there are only 4 movies, \n",
    "# vt and vt_new are the same\n",
    "vt_new = # change the shape of vt as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check your matrices against the solution\n",
    "assert u_new.shape == (20, 4), \"Oops!  The shape of the u matrix doesn't look right. It should be 20 by 4.\"\n",
    "assert s_new.shape == (4, 4), \"Oops!  The shape of the sigma matrix doesn't look right.  It should be 4 x 4.\"\n",
    "assert vt_new.shape == (4, 4), \"Oops! The shape of the v transpose matrix doesn't look right.  It should be 4 x 4.\"\n",
    "assert np.allclose(np.dot(np.dot(u_new, s_new), vt_new), user_movie_subset), \"Oops!  Something went wrong with the dot product.  Your result didn't reproduce the original movie_user matrix.\"\n",
    "print(\"That's right! The dimensions of u should be 20 x 4, and both v transpose and sigma should be 4 x 4.  The dot product of the three matrices how equals the original user-movie matrix!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the sigma matrix can actually tell us how much of the original variability in the user-movie matrix is captured by each latent feature.  The total amount of variability to be explained is the sum of the squared diagonal elements.  The amount of variability explained by the first componenet is the square of the first value in the diagonal.  The amount of variability explained by the second componenet is the square of the second value in the diagonal.   \n",
    "\n",
    "`6.` Using the above information, can you determine the amount of variability in the original user-movie matrix that can be explained by only using the first two components? Use the cell below for your work, and then test your answer against the solution with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_var = # Total variability here\n",
    "var_exp_comp1_and_comp2 = # Variability Explained by the first two components here\n",
    "perc_exp = # Percent of variability explained by the first two components here\n",
    "\n",
    "# Run the below to print your results\n",
    "print(\"The total variance in the original matrix is {}.\".format(total_var))\n",
    "print(\"Ther percentage of variability captured by the first two components is {}%.\".format(perc_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert np.round(perc_exp) == 98.55, \"Oops!  That doesn't look quite right.  You should have total variability as the sum of all the squared elements in the sigma matrix.  Then just the sum of the squared first two elements is the amount explained by the first two latent features.  Try again.\"\n",
    "print(\"Yup!  That all looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` Similar to in the previous question, change the shapes of your u, sigma, and v transpose matrices.  However, this time consider only using the first 2 components to reproduce the user-movie matrix instead of all 4. After you have your matrices set up, check your matrices against the solution by running the tests.  The matrices should have the following dimensions:\n",
    "\n",
    "$$ U_{n x k} $$\n",
    "\n",
    "$$\\Sigma_{k x k} $$\n",
    "\n",
    "$$V^T_{k x m} $$\n",
    "\n",
    "where:\n",
    "\n",
    "1. n is the number of users\n",
    "2. k is the number of latent features to keep (2 for this case)\n",
    "3. m is the number of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the dimensions of u, s, and vt as necessary to use four latent features\n",
    "# update the shape of u and store in u_new\n",
    "u_2 = # change the shape of u here\n",
    "\n",
    "# update the shape of s and store in s_new\n",
    "s_2 = #change the shape of s as necessary \n",
    "\n",
    "# Because we are using 4 latent features and there are only 4 movies, \n",
    "# vt and vt_new are the same\n",
    "vt_2 = # change the shape of vt as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that your matrices are the correct shapes\n",
    "assert u_2.shape == (20, 2), \"Oops!  The shape of the u matrix doesn't look right. It should be 20 by 2.\"\n",
    "assert s_2.shape == (2, 2), \"Oops!  The shape of the sigma matrix doesn't look right.  It should be 2 x 2.\"\n",
    "assert vt_2.shape == (2, 4), \"Oops! The shape of the v transpose matrix doesn't look right.  It should be 2 x 4.\"\n",
    "print(\"That's right! The dimensions of u should be 20 x 2, sigma should be 2 x 2, and v transpose should be 2 x 4. \\n\\n The question is now that we don't have all of the latent features, how well can we really re-create the original user-movie matrix?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`8.` When using all 4 latent features, we saw that we could exactly reproduce the user-movie matrix.  Now that we only have 2 latent features, we might measure how well we are able to reproduce the original matrix by looking at the sum of squared errors from each rating produced by taking the dot product as compared to the actual rating.  Find the sum of squared error based on only the two latent features, and use the following cell to test against the solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the dot product\n",
    "pred_ratings = # store the result of the dot product here\n",
    "\n",
    "# Compute the squared error for each predicted vs. actual rating\n",
    "sum_square_errs = # compute the sum of squared differences from each prediction to each actual value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check against the solution\n",
    "assert np.round(sum_square_errs) == 85.34, \"Oops!  That doesn't look quite right.  You should return a single number for the whole matrix.\"\n",
    "print(\"That looks right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you may be thinking... why would we want to choose a k that doesn't just give us back the full user-movie matrix with all the original ratings.  This is a good question.  One reason might be for computational reasons - sure, you may want to reduce the dimensionality of the data you are keeping, but really this isn't the main reason we would want to perform reduce k to lesser than the minimum of the number of movies or users.\n",
    "\n",
    "Let's take a step back for a second.  In this example we just went through, your matrix was very clean.  That is, for every user-movie combination, we had a rating.  **There were no missing values.** But what we know from the previous lesson is that the user-movie matrix is full of missing values.  \n",
    "\n",
    "A matrix similar to the one we just performed SVD on:\n",
    "\n",
    "<img src=\"imgs/nice_ex.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "The real world:\n",
    "\n",
    "<img src=\"imgs/real_ex.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "\n",
    "Therefore, if we keep all k latent features it is likely that latent features with smaller values in the sigma matrix will explain variability that is probably due to noise and not signal. Furthermore, if we use these \"noisey\" latent features to assist in re-constructing the original user-movie matrix it will potentially (and likely) lead to worse ratings than if we only have latent features associated with signal.   \n",
    "\n",
    "`9.` Let's try introducing just a little of the real world into this example by performing SVD on a matrix with missing values.  Below I have added a new user to our matrix who hasn't rated all four of our movies.  Try performing SVD on the new matrix.  What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This line adds one nan value as the very first entry in our matrix\n",
    "user_movie_subset.iloc[0, 0] = np.nan # no changes to this line\n",
    "\n",
    "# Try svd with this new matrix\n",
    "u, s, vt = # Compute SVD on the new matrix with the single nan value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Write your response here.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
