{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold Start Problem\n",
    "\n",
    "In the previous notebook, you learned about the **Cold Start Problem** first hand. In cases where you are introduced to a new user or new movie, collaborative flitering is not helpful as a technique to make predictions.\n",
    "\n",
    "Instead, you will need to use one of the techniques from the previous lesson like content based recommendations for new items or rank based recommendations for new users.  \n",
    "\n",
    "As a final step to completing out our recommendation system, we will build in these edge cases. Run the cell below to get started.\n",
    "\n",
    "### Matrix Factorization - Collaborative Filtering Where Possible\n",
    "\n",
    "Notice the following information is available by running the below cell:\n",
    "\n",
    "`1.` **reviews** - a dataframe of reviews\n",
    "\n",
    "`2.` **movies** - a dataframe of movies\n",
    "\n",
    "`3.` **create_train_test** - a function for creating the training and validation datasets\n",
    "\n",
    "`4.` **predict_rating** - a function that takes a user and movie and gives a prediction using FunkSVD\n",
    "\n",
    "`5.` **train_df** and **val_df** - the training and test datasets used in the previous notebook\n",
    "\n",
    "`6.` **user_mat** and **movie_mat** - the u and v matrices from FunkSVD\n",
    "\n",
    "`7.` **train_data_df** - a user-movie matrix with ratings where available.  FunkSVD was performed on this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('../data/movies_clean.csv')\n",
    "reviews = pd.read_csv('../data/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "def create_train_test(reviews, order_by, training_size, testing_size):\n",
    "    '''    \n",
    "    INPUT:\n",
    "    reviews - (pandas df) dataframe to split into train and test\n",
    "    order_by - (string) column name to sort by\n",
    "    training_size - (int) number of rows in training set\n",
    "    testing_size - (int) number of columns in the test set\n",
    "    \n",
    "    OUTPUT:\n",
    "    training_df -  (pandas df) dataframe of the training set\n",
    "    validation_df - (pandas df) dataframe of the test set\n",
    "    '''\n",
    "    reviews_new = reviews.sort_values(order_by)\n",
    "    training_df = reviews_new.head(training_size)\n",
    "    validation_df = reviews_new.iloc[training_size:training_size+testing_size]\n",
    "    \n",
    "    return training_df, validation_df\n",
    "\n",
    "def predict_rating(user_matrix, movie_matrix, user_id, movie_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_matrix - user by latent factor matrix\n",
    "    movie_matrix - latent factor by movie matrix\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according the movies df\n",
    "    \n",
    "    OUTPUT:\n",
    "    pred - the predicted rating for user_id-movie_id according to FunkSVD\n",
    "    '''\n",
    "    # Create series of users and movies in the right order\n",
    "    user_ids_series = np.array(train_data_df.index)\n",
    "    movie_ids_series = np.array(train_data_df.columns)\n",
    "    \n",
    "    # User row and Movie Column\n",
    "    user_row = np.where(user_ids_series == user_id)[0][0]\n",
    "    movie_col = np.where(movie_ids_series == movie_id)[0][0]\n",
    "    \n",
    "    # Take dot product of that row and column in U and V to make prediction\n",
    "    pred = np.dot(user_matrix[user_row, :], movie_matrix[:, movie_col])\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# Use our function to create training and test datasets\n",
    "train_df, val_df = create_train_test(reviews, 'date', 8000, 2000)\n",
    "\n",
    "# Create user-by-item matrix - this will keep track of order of users and movies in u and v\n",
    "train_user_item = train_df[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "train_data_np = np.array(train_data_df)\n",
    "\n",
    "# Read in user and movie matrices\n",
    "user_file = open(\"user_matrix\", 'rb')\n",
    "user_mat = pickle.load(user_file)\n",
    "user_file.close()\n",
    "\n",
    "movie_file = open(\"movie_matrix\", 'rb')\n",
    "movie_mat = pickle.load(movie_file)\n",
    "movie_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Predictions\n",
    "\n",
    "Unfortunately, you weren't able to make predictions on every user-movie combination in the test set, as some of these users or movies were new.  \n",
    "\n",
    "However, you can validate your predictions for the user-movie pairs that do exist in the user_mat and movie_mat matrices.  \n",
    "\n",
    "`1.` Complete the function below to see how far off we were on average across all of the predicted ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_comparison(val_df, user_mat=user_mat, movie_mat=movie_mat):\n",
    "    '''\n",
    "    INPUT:\n",
    "    val_df - the validation dataset created in the third cell above\n",
    "    user_mat - U matrix in FunkSVD\n",
    "    movie_mat - V matrix in FunkSVD\n",
    "        \n",
    "    OUTPUT:\n",
    "    rmse - RMSE of how far off each value is from it's predicted value\n",
    "    perc_rated - percent of predictions out of all possible that could be rated\n",
    "    actual_v_pred - a 10 x 10 grid with counts for actual vs predicted values\n",
    "    preds - (list) predictions for any user-movie pairs where it was possible to make a prediction\n",
    "    acts - (list) actual values for any user-movie pairs where it was possible to make a prediction\n",
    "    '''\n",
    "\n",
    "    return rmse, perc_rated, actual_v_pred, preds, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well did we do? # Make some plots and calculate some statistics to \n",
    "# understand how well this technique is working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` We didn't do so bad on making those predictions!  But, how many user-movie pairs were we unable to make predictions for?  Use the cell below to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based For New Movies\n",
    "\n",
    "If all of the above went well, you will notice we still have work to do!  We need to bring in a few things we picked up from the last lesson to use for those new users and movies.  Below is the code used to make the content based recommendations, which found movies that were similar to one another.  This was from **5_Content_Based_Recommendations** in the previous lesson.\n",
    "\n",
    "The below function **find_similar_movies** will provide similar movies to any movie based only on content.  \n",
    "\n",
    "Run the cell below to gain access to the content based similarity functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subset so movie_content is only using the dummy variables for each genre and the 3 century based year dummy columns\n",
    "movie_content = np.array(movies.iloc[:,4:])\n",
    "\n",
    "# Take the dot product to obtain a movie x movie matrix of similarities\n",
    "dot_prod_movies = movie_content.dot(np.transpose(movie_content))\n",
    "\n",
    "\n",
    "def find_similar_movies(movie_id):\n",
    "    '''\n",
    "    INPUT\n",
    "    movie_id - a movie_id \n",
    "    OUTPUT\n",
    "    similar_movies - an array of the most similar movies by title\n",
    "    '''\n",
    "    # find the row of each movie id\n",
    "    movie_idx = np.where(movies['movie_id'] == movie_id)[0][0]\n",
    "    \n",
    "    # find the most similar movie indices - to start I said they need to be the same for all content\n",
    "    similar_idxs = np.where(dot_prod_movies[movie_idx] == np.max(dot_prod_movies[movie_idx]))[0]\n",
    "    \n",
    "    # pull the movie titles based on the indices\n",
    "    similar_movies = np.array(movies.iloc[similar_idxs, ]['movie'])\n",
    "    \n",
    "    return similar_movies\n",
    "    \n",
    "    \n",
    "def get_movie_names(movie_ids):\n",
    "    '''\n",
    "    INPUT\n",
    "    movie_ids - a list of movie_ids\n",
    "    OUTPUT\n",
    "    movies - a list of movie names associated with the movie_ids\n",
    "    \n",
    "    '''\n",
    "    movie_lst = list(movies[movies['movie_id'].isin(movie_ids)]['movie'])\n",
    "   \n",
    "    return movie_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Based For New Users\n",
    "\n",
    "From the above two code cells, we have a way to make recommendations for movie-user pairs that have ratings in any part of our user-movie matrix.  We also have a way to make ratings for movies that have never received a rating using movie similarities.\n",
    "\n",
    "In this last part here, we need a way to make recommendations to new users.  For this, our functions from **2_Most_Popular_Recommendations** in Lesson 1 will come in handy.  Run the cell below to have these functions available.\n",
    "\n",
    "Run the cell below to gain access to the rank based functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ranked_df(movies, reviews):\n",
    "        '''\n",
    "        INPUT\n",
    "        movies - the movies dataframe\n",
    "        reviews - the reviews dataframe\n",
    "        \n",
    "        OUTPUT\n",
    "        ranked_movies - a dataframe with movies that are sorted by highest avg rating, more reviews, \n",
    "                        then time, and must have more than 4 ratings\n",
    "        '''\n",
    "        \n",
    "        # Pull the average ratings and number of ratings for each movie\n",
    "        movie_ratings = reviews.groupby('movie_id')['rating']\n",
    "        avg_ratings = movie_ratings.mean()\n",
    "        num_ratings = movie_ratings.count()\n",
    "        last_rating = pd.DataFrame(reviews.groupby('movie_id').max()['date'])\n",
    "        last_rating.columns = ['last_rating']\n",
    "\n",
    "        # Add Dates\n",
    "        rating_count_df = pd.DataFrame({'avg_rating': avg_ratings, 'num_ratings': num_ratings})\n",
    "        rating_count_df = rating_count_df.join(last_rating)\n",
    "\n",
    "        # merge with the movies dataset\n",
    "        movie_recs = movies.set_index('movie_id').join(rating_count_df)\n",
    "\n",
    "        # sort by top avg rating and number of ratings\n",
    "        ranked_movies = movie_recs.sort_values(['avg_rating', 'num_ratings', 'last_rating'], ascending=False)\n",
    "\n",
    "        # for edge cases - subset the movie list to those with only 5 or more reviews\n",
    "        ranked_movies = ranked_movies[ranked_movies['num_ratings'] > 4]\n",
    "        \n",
    "        return ranked_movies\n",
    "    \n",
    "\n",
    "def popular_recommendations(user_id, n_top, ranked_movies):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id (str) of the individual you are making recommendations for\n",
    "    n_top - an integer of the number recommendations you want back\n",
    "    ranked_movies - a pandas dataframe of the already ranked movies based on avg rating, count, and time\n",
    "\n",
    "    OUTPUT:\n",
    "    top_movies - a list of the n_top recommended movies by movie title in order best to worst\n",
    "    '''\n",
    "\n",
    "    top_movies = list(ranked_movies['movie'][:n_top])\n",
    "\n",
    "    return top_movies\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now For Your Task\n",
    "\n",
    "The above cells set up everything we need to use to make predictions.  Your task is to write a function, which uses the above information as necessary to provide recommendations for every user in the **val_df** dataframe.  There isn't one right way to do this, but using a blend between the three could be your best bet.  \n",
    "\n",
    "You can see the blended approach I used in the video on the next page, but feel free to be creative with your solution!\n",
    "\n",
    "`3.` Use the function below along with the document strings to assist with completing the task for this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_recommendations(_id, _id_type='movie', train_data=train_data_df, \n",
    "                         train_df=train_df, movies=movies, rec_num=5, user_mat=user_mat):\n",
    "    '''\n",
    "    INPUT:\n",
    "    _id - either a user or movie id (int)\n",
    "    _id_type - \"movie\" or \"user\" (str)\n",
    "    train_data - dataframe of data as user-movie matrix\n",
    "    train_df - dataframe of training data reviews\n",
    "    movies - movies df\n",
    "    rec_num - number of recommendations to return (int)\n",
    "    user_mat - the U matrix of matrix factorization\n",
    "    movie_mat - the V matrix of matrix factorization\n",
    "    \n",
    "    OUTPUT:\n",
    "    rec_ids - (array) a list or numpy array of recommended movies by id                  \n",
    "    rec_names - (array) a list or numpy array of recommended movies by name\n",
    "    '''\n",
    "\n",
    "    \n",
    "    return rec_ids, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these cells to see that you can truly predict for everyone in the test set\n",
    "# Do you see anything insightful?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use this cell to discuss your findings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
