{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting It All Together\n",
    "\n",
    "As you might have guessed from the last notebook, using all of the variables was allowing you to drastically overfit the training data.  This was great for looking good in terms of your Rsquared on these points.  However, this was not great in terms of how well you were able to predict on the test data.\n",
    "\n",
    "We will start where we left off in the last notebook.  First read in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import AllTogether as t\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('./survey_results_public.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "**1.** To begin fill in the format function below with the correct variable.  Notice each **{ }** holds a space where one of your variables will be added to the string.  This will give you something to do while the the function does all the steps you did throughout this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'test_score'\n",
    "b = 'train_score'\n",
    "c = 'linear model (lm_model)'\n",
    "d = 'X_train and y_train'\n",
    "e = 'X_test'\n",
    "f = 'y_test'\n",
    "g = 'train and test data sets'\n",
    "h = 'overfitting'\n",
    "\n",
    "q1_piat = '''In order to understand how well our {} fit the dataset, \n",
    "            we first needed to split our data into {}.  \n",
    "            Then we were able to fit our {} on the {}.  \n",
    "            We could then predict using our {}  by providing \n",
    "            the linear model the {} for it to make predictions.  \n",
    "            These predictions were for {}. \n",
    "\n",
    "            By looking at the {}, it looked like we were doing awesome because \n",
    "            it was 1!  However, looking at the {} suggested our model was not \n",
    "            extending well.  The purpose of this notebook will be to see how \n",
    "            well we can get our model to extend to new data.\n",
    "            \n",
    "            This problem where our data fits the training data well, but does\n",
    "            not perform well on test data is commonly known as \n",
    "            {}.'''.format(c, g, c, d, c, e, f, b, a, h)\n",
    "\n",
    "print(q1_piat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the solution order of the letters in the format\n",
    "t.q1_piat_answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "**2.** Now, we need to improve the model . Use the dictionary below to provide the true statements about improving **this model**.  **Also consider each statement as a stand alone**.  Though, it might be a good idea after other steps, which would you consider a useful **next step**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'yes'\n",
    "b = 'no'\n",
    "\n",
    "q2_piat = {'add interactions, quadratics, cubics, and other higher order terms': b, \n",
    "           'fit the model many times with different rows, then average the responses': a,\n",
    "           'subset the features used for fitting the model each time': a,\n",
    "           'this model is hopeless, we should start over': b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check your solution\n",
    "t.q2_piat_check(q2_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3\n",
    "\n",
    "**3.** Before we get too far along, follow the steps in the function below to create the X (explanatory matrix) and y (response vector) to be used in the model.  If your solution is correct, you should see a plot similar to the one shown in the Screencast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "    \n",
    "    OUTPUT\n",
    "    X - A matrix holding all of the variables you want to consider when predicting the response\n",
    "    y - the corresponding response vector\n",
    "    \n",
    "    This function cleans df using the following steps to produce X and y:\n",
    "    1. Drop all the rows with no salaries\n",
    "    2. Create X as all the columns that are not the Salary column\n",
    "    3. Create y as the Salary column\n",
    "    4. Drop the Salary, Respondent, and the ExpectedSalary columns from X\n",
    "    5. For each numeric variable in X, fill the column with the mean value of the column.\n",
    "    6. Create dummy columns for all the categorical variables in X, drop the original columns\n",
    "    '''\n",
    "    # Drop rows with missing salary values\n",
    "    df = df.dropna(subset=['Salary'], axis=0)\n",
    "    y = df['Salary']\n",
    "    \n",
    "    #Drop respondent and expected salary columns\n",
    "    df = df.drop(['Respondent', 'ExpectedSalary', 'Salary'], axis=1)\n",
    "    \n",
    "    # Fill numeric columns with the mean\n",
    "    num_vars = df.select_dtypes(include=['float', 'int']).columns\n",
    "    for col in num_vars:\n",
    "        df[col].fillna((df[col].mean()), inplace=True)\n",
    "        \n",
    "    # Dummy the categorical variables\n",
    "    cat_vars = df.select_dtypes(include=['object']).copy().columns\n",
    "    for var in  cat_vars:\n",
    "        # for each cat add dummy var, drop original column\n",
    "        df = pd.concat([df.drop(var, axis=1), pd.get_dummies(df[var], prefix=var, prefix_sep='_', drop_first=True)], axis=1)\n",
    "    \n",
    "    X = df\n",
    "    return X, y\n",
    "    \n",
    "#Use the function to create X and y\n",
    "X, y = clean_data(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoffs here pertains to the number of missing values allowed in the used columns.\n",
    "#Therefore, lower values for the cutoff provides more predictors in the model.\n",
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 25]\n",
    "\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = t.find_optimal_lm_mod(X, y, cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "**4.** Use the output and above plot to correctly fill in the keys of the **q4_piat** dictionary with the correct variable.  Notice that only the optimal model results are given back in the above - they are stored in **lm_model**, **X_train**, **X_test**, **y_train**, and **y_test**.  If more than one answer holds, provide a tuple holding all the correct variables in the order of first variable alphabetically to last variable alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape[1]) #Number of columns\n",
    "print(r2_scores_test[np.argmax(r2_scores_test)]) # The model we should implement test_r2\n",
    "print(r2_scores_train[np.argmax(r2_scores_test)]) # The model we should implement train_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'we would likely have a better rsquared for the test data.'\n",
    "b = 1000\n",
    "c = 872\n",
    "d = 0.69\n",
    "e = 0.82\n",
    "f = 0.88\n",
    "g = 0.72\n",
    "h = 'we would likely have a better rsquared for the training data.'\n",
    "\n",
    "q4_piat = {'The optimal number of features based on the results is': c, \n",
    "               'The model we should implement in practice has a train rsquared of': e, \n",
    "               'The model we should implement in practice has a test rsquared of': d,\n",
    "               'If we were to allow the number of features to continue to increase': h\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check against your solution\n",
    "t.q4_piat_check(q4_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "\n",
    "**5.** The default penalty on coefficients using linear regression in sklearn is a ridge (also known as an L2) penalty.  Because of this penalty, and that all the variables were normalized, we can look at the size of the coefficients in the model as an indication of the impact of each variable on the salary.  The larger the coefficient, the larger the expected impact on salary.  \n",
    "\n",
    "Use the space below to take a look at the coefficients.  Then use the results to provide the **True** or **False** statements based on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df\n",
    "\n",
    "#Use the function\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "#A quick look at the top results\n",
    "coef_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = True\n",
    "b = False\n",
    "\n",
    "#According to the data...\n",
    "q5_piat = {'Country appears to be one of the top indicators for salary': a,\n",
    "               'Gender appears to be one of the indicators for salary': b, \n",
    "               'How long an individual has been programming appears to be one of the top indicators for salary': a,\n",
    "               'The longer an individual has been programming the more they are likely to earn': b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.q5_piat_check(q5_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congrats of some kind\n",
    "\n",
    "Congrats!  Hopefully this was a great review, or an eye opening experience about how to put the steps together for an analysis.  List the steps.  In the next lesson, you will look at how take this and show it off to others so they can act on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
